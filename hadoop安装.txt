/*安装Java*/
下载jdk-8u171-linux-x64.tar.gz
在/usr/local/下mkdir java
把jdk-8u171-linux-x64.tar.gz移动到/usr/local/java下
tar -zxvf jdk-8u171-linux-x64.tar.gz
修改/etc/profile,在末尾添加
export JAVA_HOME=/usr/local/java/jdk8
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
export PATH=$JAVA_HOME/bin:$PATH
等号与变量和路径之间不要加空格

/*hadoop用户生成*/
1.安装好jdk8
2.# useradd -m hadoop -s /bin/bash # 创建新用户hadoop (useradd hadoop -g hadoop创建hadoop并添加给hadoop组)(-m 自动建立用户的登入目录，-s指定用户登录后使用的shell,userdel -f zzz删除用户zzz连同目录一起删除)
3.# passwd hadoop  修改用户的密码(广思hadoop密码：hadoop)
4.# visudo 为用户增加管理员权限
找到 root ALL=(ALL) ALL 这行在这行下面增加一行内容：hadoop ALL=(ALL) ALL（当中的间隔为tab）
5.以hadoop登录，直接su hadoop不行，可以重启后以hadoop登录或logout命令
6.$ ssh localhost 测试一下 SSH 是否可用，然后退出刚才的 ssh
7.$ cd ~/.ssh/	# 若没有该目录，请先执行一次ssh localhost
8.$ ssh-keygen -t rsa	# 会有提示，都按回车就可以
9.$ cat id_rsa.pub >> authorized_keys  # 加入授权
10.$ chmod 600 ./authorized_keys    # 修改文件权限
   再用 ssh localhost 命令，无需输入密码就可以直接登陆了

/*单台机器hadoop安装*/
11.移动hadoop-2.8.4.tar.gz到/usr/local/
12.sudo tar -zvxf hadoop-2.8.4.tar.gz
13.sudo mv ./hadoop-2.6.5/ ./hadoop # 将文件夹名改为hadoop
14.sudo chown -R hadoop:hadoop ./hadoop # 修改文件权限
15.修改环境变量：
	export HADOOP_HOME=/usr/local/hadoop
	export PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH

/*haddoop集群*/
15.上述操作在所有机器走一遍
16.$ sudo vim /etc/hostname  //为了便于区分，可以修改各个节点的主机名
 添加HOSTNAME=Master.    //其它主机也对应修改为HOSTNAME=Slave1,HOSTNAME=Slave2....
17.$ sudo vim /etc/hosts //修改自己所用节点的IP映射,所有主机都需要修改
  添加: 192.168.5.114 Master
       192.168.5.115 Slave1
       192.168.5.116 Slave2
18.修改了主机名要重启：shutdown -r now

/*SSH无密码登陆节点,让 Master 节点可以无密码 SSH 登陆到各个 Slave 节点上*/
18.重新生成公匙，因为改过主机名，所以还需要删掉原有的再重新生成一次
	$ cd ~/.ssh               # 如果没有该目录，先执行一次ssh localhost
	$ rm ./id_rsa*            # 删除之前生成的公匙（如果有）
	$ ssh-keygen -t rsa       # 一直按回车就可以
	$ cat ./id_rsa.pub >> ./authorized_keys
19. Master 节点将上公匙传输到 Slave1, Slave2 节点
	$ scp ~/.ssh/id_rsa.pub hadoop@Slave1:/home/hadoop/
20.在 Slave1 节点上，将 ssh 公匙加入授权：
	$ cat ~/id_rsa.pub >> ~/.ssh/authorized_keys
	$ rm ~/id_rsa.pub    # 用完就可以删掉了
21.在 Master 节点上就可以无密码 SSH 到各个 Slave 节点了，可在 Master 节点上执行如下命令进行检验：
	$ ssh Slave1

/*修改配置文件*/
(查看端口占用netstat -anp|grep 9200,8020,50090)
22.修改 /usr/local/hadoop/etc/hadoop 中的5个配置文件， slaves、core-site.xml、hdfs-site.xml、mapred-site.xml、yarn-site.xml 
23.文件slaves，将作为 DataNode 的主机名写入该文件，每行一个，默认为 localhost，分布式配置可以保留 localhost，也可以删掉，让 Master 节点仅作为 NameNode 使用。我们把localhost保留，再添加Slave1，Slave2.
24.修改 core-site.xml:
<configuration>
        <property>
                <name>fs.defaultFS</name>
                <value>hdfs://Master:8020</value>
        </property>
        <property>
                <name>hadoop.tmp.dir</name>
                <value>/usr/local/hadoop/tmp</value>
                <description>Abase for other temporary directories.</description>
        </property>
</configuration>
（备注：请先在 /usr/local/hadoop 目录下建立 tmp 文件夹）
25.文件 hdfs-site.xml
<configuration>
        <property>
                <name>dfs.namenode.secondary.http-address</name>
                <value>Master:50090</value>
        </property>
        <property>
                <name>dfs.replication</name>
                <value>1</value>
        </property>
        <property>
                <name>dfs.namenode.name.dir</name>
                <value>/usr/local/hadoop/tmp/dfs/name</value>
        </property>
        <property>
                <name>dfs.datanode.data.dir</name>
                <value>/usr/local/hadoop/tmp/dfs/data</value>
        </property>
</configuration>
（备注：请先在 /usr/local/hadoop 目录下建立 tmp/dfs/name,tmp/dfs/data 文件夹）
26.mapred-site.xml （可能需要先重命名，默认文件名为 mapred-site.xml.template），然后配置修改如下：
<configuration>
        <property>
                <name>mapreduce.framework.name</name>
                <value>yarn</value>
        </property>
</configuration>
27.文件 yarn-site.xml：
<configuration>
        <property>
                <name>yarn.resourcemanager.hostname</name>
                <value>Master</value>
        </property>
        <property>
                <name>yarn.nodemanager.aux-services</name>
                <value>mapreduce_shuffle</value>
        </property>
</configuration>
27.如果有其他 Slave 节点,所有节点配置都一样，拷贝过去就行。
28.格式化namenode：$hadoop namenode -format（只需要执行一次即可）(重新格式化请先删除/usr/local/hadoop/tmp)
	执行过程不报错，最后是
        /***********************************************************
	SHUTDOWN_MSG:Shutting down NameNode at Master/192.168.5.114
	************************************************************/
29.启动hadoop：$start-all.sh
 如果报错JAVA_HOME is not set and could not be found
 修改hadoop-env.sh中，JAVA_HOME
 export JAVA_HOME=${JAVA_HOME}
 改为：export JAVA_HOME=/usr/local/java/jdk8

 如果出现：namenode running as process xxxx. Stop it first.
 需要stop掉所有的hadoop服务；解决：重启电脑。shutdown -r now	
30.如果没有再报错，使用jps查看节点启动情况
$jps
2000 Jps
1586 SecondaryNameNode
1739 ResourceManager
1390 NameNode
其它节点也运行$jps也会看到相应信息。
Master上的进程：NameNode，SecondaryNameNode，ResourceManager。 
Slaves上的进程：DataNode，NodeManager。
31.在master访问管理页面：http://192.168.5.114:50070/
   集群信息：http://192.168.5.114:8088
   如果访问不了，请关闭防火墙。

/*单词统计的测试wordcount*/
32.测试
$vi testWordCount 创建文件随便写点东西进去。
$ hadoop fs -mkdir /home/hadoop/input 在hdfs中创建文件夹 
$ hadoop fs -ls /home/hadoop/ 查看创建的文件夹
$hadoop fs -put testWordCount /home/hadoop/input //把刚创建的testWordCount文件上传到hdfs.
如果出现testwordcount._copying_ could only be replicated to 0 nodes的问题，请关闭防火墙，master和slave的都要关。systemctl stop firewalld，禁止systemctl  disable firewalld，查看firewall-cmd --state
$hadoop jar /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2,8,4.jar wordcount /home/hadoop/input/* /home/hadoop/output
已经编译好的WordCount的Jar在/usr/local/hadoop/share/hadoop/mapreduce目录下，其中/usr/local/hadoop是hadoop的安装目录
$hadoop fs -ls /home/hadoop/output	查看output内容
会存在两个文件xxx/_SUCCESS,xxx/part-r-00000
$hadoop fs -cat output/part-r-00000 //查看统计结果
/*
hadoop fs: 可以用于其他文件系统，不止是hdfs文件系统内,该命令的使用范围更广.
hadoop dfs :专门针对hdfs分布式文件系统.
hdfs dfs :和上面作用相同，更为推荐此命令，当使用hadoop dfs时内部会被转为hdfs dfs命令。
*/

/*
jar
运行jar文件。用户可以把他们的Map Reduce代码捆绑到jar文件中，使用这个命令执行。

用法：hadoop jar <jar> [mainClass] args...
*/


/*IDEA编写java hadoop程序*/
1.创建一个Maven项目，填写Maven的GroupId和ArtifactId（根据自己的项目随便填，点击Next）
groupId一般分为多个段，这里我只说两段，第一段为域，第二段为公司名称。我一般会将groupId设置为top.hellozwj，表示域，hellozwj是我个人姓名缩写。artifactId设置为test_hadoop，表示你这个项目的名称是test_hadoop。
2.配置依赖
apache源
在project内尾部添加
<repositories>
    <repository>
        <id>apache</id>
        <url>http://maven.apache.org</url>
    </repository>
</repositories>
阿里云仓库：
要修改maven根目录下的setting.xml文件(maven根目录在${user.home}/.m2/，修改下面的settings.xml配置本地仓库路径，没有settings这个xml文件就新建，在settings下build,execution,deployment下build tools下maven，通过user settings file可以修改settings.xml)
/*settings.xml
<settings xmlns="http://maven.apache.org/SETTINGS/1.0.0"
            xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
            xsi:schemaLocation="http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd">
/*
<mirrors>
        <!-- 阿里云仓库 -->
        <mirror>
            <id>alimaven</id>
            <mirrorOf>central</mirrorOf>
            <name>aliyun maven</name>
            <url>http://maven.aliyun.com/nexus/content/repositories/central/</url>
        </mirror>
        <!-- 中央仓库1 -->
        <mirror>
            <id>repo1</id>
            <mirrorOf>central</mirrorOf>
            <name>Human Readable Name for this Mirror.</name>
            <url>http://repo1.maven.org/maven2/</url>
        </mirror>
    
        <!-- 中央仓库2 -->
        <mirror>
            <id>repo2</id>
            <mirrorOf>central</mirrorOf>
            <name>Human Readable Name for this Mirror.</name>
            <url>http://repo2.maven.org/maven2/</url>
        </mirror>
</mirrors> 
也可以在pom.xml添加：
<repositories><!-- 代码库 -->
        <repository>
            <id>maven-ali</id>
            <url>http://maven.aliyun.com/nexus/content/groups/public//</url>
            <releases>
                <enabled>true</enabled>
            </releases>
            <snapshots>
                <enabled>true</enabled>
                <updatePolicy>always</updatePolicy>
                <checksumPolicy>fail</checksumPolicy>
            </snapshots>
        </repository>
</repositories>
添加hadoop依赖：
基础依赖hadoop-core和hadoop-common；如果需要读写HDFS，则还需要依赖hadoop-hdfs和hadoop-client；如果需要读写HBase，则还需要依赖hbase-client。
在project内尾部添加
<dependencies>
    <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-core</artifactId>//2.x之后不需要这个包，用hadoop-client和hadoop-hdfs两个依赖项取代
        <version>1.2.1</version>
    </dependency>
    <dependency>
        <groupId>org.apache.hadoop</groupId>
        <artifactId>hadoop-common</artifactId>
        <version>2.8.4</version>
    </dependency>
</dependencies>
//Hadoop版本为2.8.4，所以这里的maven的Hadoop版本必须对应




-----------------hadoop cdh---------------
1、cdh比原生的Apache发行版本包含了更多的补丁，用于增强稳定性，改善功能，有时候还增加功能特性 
2、cdh版本是由cloudera公司开源的，可以使用cm平台进行管理，比原生的Apache版本安装、维护更加省力 
3、但是对技术人员的要求更高，必须对原生apache版本的各个组件理解清晰 
4、在cm管理平台中，cdh的parcel包不包含某些组件，需要自己下载对应的parcel包，比如说kafka 
5、对hdfs部署过程中，对磁盘进行lvm卷轴或者是磁盘目录统一，对于多台机器，否则之后维护成本高

安装操作系统：
(vbox虚拟机选择linux2.6/3.x/4.x(64bit)不要选redhat，master内存要不少于6个G，slave不少于3个G)

1.安装jdk
修改/etc/profile,在末尾添加
export JAVA_HOME=/usr/local/java/jdk8
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
export PATH=$JAVA_HOME/bin:$PATH
在/usr下创建java目录，然后添加软连接
ln -s /usr/local/java  /usr/java/default

2.配置hosts
vi /etc/hosts
192.168.2.200 master
192.168.2.201 slave1
192.168.2.202 slave2

3.配置ssh免密码
cd  ~/.ssh/	# 若没有该目录，请先执行一次ssh localhost
#ssh-keygen -t rsa	# 会有提示，都按回车就可以
#scp  id_rsa.pub root@192.168.2.201:/home
#cat /home/id_rsa.pub >> ~/.ssh/authorized_keys  # 加入授权,在192.168.2.201上操作
(202执行同样的操作)
#ssh root@192.168.2.201 #测试是否可以免密码登录，在192.168.2.200上操作
（201，200上同样进行上面操作使免密码登录）

4.ntp服务配置（所有节点安装相关组件）（如果已经保证时间同步，此步骤可跳过）
yum -y install ntp ntpdate

5.在主节点安装mysql
https://cdn.mysql.com//Downloads/MySQL-5.7/mysql-5.7.24-linux-glibc2.12-x86_64.tar.gz
tar -zxvf mysql-xxxxx.glic.xxx//解压
mv mysql.xxxx.glic.xxx mysql //改名
cd mysql
Vi /etc/my.cnf
[mysql] 
# 设置mysql客户端默认字符集 
default-character-set=utf8  
socket=/var/lib/mysql/mysql.sock 
[mysqld] 
#skip-name-resolve 
#设置3306端口 
port = 3306  
socket=/var/lib/mysql/mysql.sock 
# 设置mysql的安装目录 
basedir=/usr/local/mysql 
# 设置mysql数据库的数据的存放目录 
datadir=/usr/local/mysql/data 
# 允许最大连接数 
max_connections=200 
# 服务端使用的字符集默认为8比特编码的latin1字符集 
character-set-server=utf8 
# 创建新表时将使用的默认存储引擎 
default-storage-engine=INNODB 
#lower_case_table_name=1 
max_allowed_packet=16M

创建mysql用户组：
groupadd mysql
添加mysql用户：
useradd -r -g mysql mysql

在mysql文件夹下：
mkdir data
创建文件夹：
mkdir /var/lib/mysql
chmod -R 777 /var/lib/mysql
更改mysql文件目录所有者：
chown -R mysql:mysql mysql/
./bin/mysqld --initialize --user=mysql
会有一行：
2018-06-01T02:10:16.805014Z 1 [Note] A temporary password is generated for root@localhost:   gysQ5dRwr6/j
gysQ5dRwr6/j是初始的随机密码。
设置开机启动：
1.复制启动脚本 cp ./support-files/mysql.server /etc/rc.d/init.d/mysqld
2.增加mysqld服务控制脚本执行权限 chmod +x /etc/rc.d/init.d/mysqld 
3.增加mysqld服务到系统服务  chkconfig --add mysqld
4.检查mysqld服务是否生效 chkconfig --list mysqld
出现以下则，正常了：
mysqld         	0:off	1:off	2:on	3:on	4:on	5:on	6:off
启动mysql服务：
service mysqld start
测试登陆：
mysql -u root -p
登上后，请修改密码：
set password = password("uestc@123456");
运行远程登录：
grant all privileges on *.* to root@'%' identified by 'uestc@123456' ;
grant all privileges on *.* to root@'%' identified by 'uestc@123456' WITH GRANT OPTION;
flush privileges;

创建以下数据库
create database hive DEFAULT CHARSET utf8 COLLATE utf8_general_ci;
create database oozie DEFAULT CHARACTER SET utf8; 
create database amon DEFAULT CHARSET utf8 COLLATE utf8_general_ci;
create database hue DEFAULT CHARSET utf8 COLLATE utf8_general_ci;

下载mysql-connector-java.jar,并保存到所有主机的/usr/share/java目录下
https://cdn.mysql.com//Downloads/Connector-J/mysql-connector-java-5.1.47.tar.gz
没有/usr/share/java目录，请自行创建


6.官网下载Cloudera Manager和CDH
Cloudera Manager下载地址：
http://archive.cloudera.com/cm5/cm/5/
cloudera-manager-centos7-cm5.15.1_x86_64.tar.gz
CDH安装包:
http://archive.cloudera.com/cdh5/parcels/latest/
CDH-5.11.0-1.cdh5.15.1.p0.34-el6.parcel
CDH-5.11.0-1.cdh5.15.1.p0.34-el6.parcel.sha1
manifest.json
(manager与CDH版本要一致，vbox虚拟机选择linux2.6/3.x/4.x(64bit)不要选redhat)

解压cloudera-manager-centos7-cm5.15.1_x86_64.tar.gz解压后会出现cloudera,cm-5.15.1两个目录
mv cloudera /opt
mv cm-5.15.1 /opt
复制mysql-connector-java.jar到目录/opt/cm-5.15.1/share/cmf/lib/

7.创建用户cloudera-scm（所有节点操作）
由于Cloudera Manager和Managed Services默认使用cloudera-scm，所以需要创建此用户
useradd --system --no-create-home --shell=/bin/false --comment "Cloudera SCM User" cloudera-scm

8.agent配置
修改/opt/cm-5.15.1/etc/cloudera-scm-agent/config.ini中的server_host为主节点的主机名。
# Hostname of the CM server.
server_host=master

9.在主节点初始化CM5数据库
/opt/cm-5.15.1/share/cmf/schema/scm_prepare_database.sh mysql cm -h master -uroot -puestc@123456 --scm-host master scm scm scm

mysql后到cm随便取名字，mysql会创建一个cm的数据库
-h后是mysql的主机名
--scm-host 后是SCM server的主机名（主节点）
(注意：-uroot，u和root不空格 -puestc@123456，p和uestc@123456不空格)

10.准备Parcels，用以安装CDH5,(只主节点)
将CHD5相关的Parcel包放到主节点的/opt/cloudera/parcel-repo/目录中
cp CDH-5.15.1-1.cdh5.15.1.p0.4-el5.parcel /opt/cloudera/parcel-repo/
cp CDH-5.15.1-1.cdh5.15.1.p0.4-el5.parcel.sha1 /opt/cloudera/parcel-repo/
cp manifest.json /opt/cloudera/parcel-repo/
相关的文件如下：
CDH-5.15.1-1.cdh5.11.0.p0.34-el6.parcel
CDH-5.15.1-1.cdh5.11.0.p0.34-el6.parcel.sha1
manifest.json
最后将xxx.parcel.sha1，重命名为xxx.parcel.sha
mv /opt/cloudera/parcel-repo/CDH-5.15.1-1.cdh5.15.1.p0.4-el5.parcel.sha1 /opt/cloudera/parcel-repo/CDH-5.15.1-1.cdh5.15.1.p0.4-el5.parcel.sha

11.启动主节点的CM  Server和所有节点的Agent
主节点：通过/opt/cm-5.15.1/etc/init.d/cloudera-scm-server start启动服务端。
所有节点（包括主节点）：通过/opt/cm-5.15.1/etc/init.d/cloudera-scm-agent start启动Agent服务
停止可以用/cloudera-scm-server stop
(问题：
cloudera-scm-agent start Starting 
cloudera-scm-agent: [FAILED]
解决：查看日志
cd /opt/cm-5.7.0/log/cloudera-scm-agent/ 
cat cloudera-scm-agent.out
如果提示python有问题，请使用cloudera-manager-centos7，而不是el版的
)

12.访问http://192.168.2.200:7180/cmf/login
用户名：admin，密码：admin
注意选免费版，回退很难
删除cm数据库，重新初始化。
 问题：Parcel不可用于操作系统分配RHEL7
 解决：manager与CDH版本要一致，vbox虚拟机选择linux2.6/3.x/4.x(64bit)不要选redhat
 问题：出现主机运行状态不良情况
 解决：rm -f /opt/cm-5.15.1/lib/cloudera-scm-agent/cm_guid (每个节点)
     /opt/cm-5.15.1/etc/init.d/cloudera-scm-agent restart
 问题：Cloudera 建议将 /proc/sys/vm/swappiness 设置为最大值 10
      echo 'vm.swappiness=10'>> /etc/sysctl.conf

1)选择安装服务
我选择的‘所有服务’
2）集群设置角色分配，没特殊要求的话，选默认即可，点继续
3）数据库设置
请使用安装mysql时创建的数据库,点击连接测试，当全部都显示Successful，点击继续
4)群集设置,审核更改,选择默认，点击继续

find / -type f -name "*cc.sh"
定位到编辑 vim /opt/cm-5.15.1/lib64/cmf/service/client/deploy-cc.sh
直接在上面加上
JAVA_HOME=/usr/local/java
export JAVA_HOME=/usr/local/java
所有节点都这样设置一下

安装失败后：
删除mysql下的cm数据库，重新初始化，重启server, agent

问题：安装CDH找不到java_home的错误
jdk的时候,应该要安装到/usr/java目录
ln -s /usr/local/java  /usr/java/default

安装好后cloudera-scm-server启动很慢，大概6分钟

问题：hue webUI无法访问，请在cloudera manager主页点击hue，在hue的配置下点击‘端口和地址’，勾选将 Hue 服务器绑定到通配符地址，重启服务。
（注：hdfs的50070，spark,yarn等都是因为没有把端口是和外网地址绑定，所以把端口的地址都绑定到0.0.0.0，外网才能访问）
问题：hdfs副本不足的块
dfs. replication属性默认是3，也就是说副本数---块的备份数默认为3份。但是我们这里集群只有两个DataNode.
点击HDFS-配置,在搜索框搜索dfs. replication，设置为2后保存更改

13.介绍
JobHistoryServer
         历史服务器，管理者可以通过历史服务器查看已经运行完成的Mapreduce作业记录，比如用了多少个Map、多少个Reduce、作业提交时间、作业启动时间、作业完成时间等信息。
Impala
	Impala是Cloudera公司主导开发的新型查询系统，它提供SQL语义，能查询存储在Hadoop的HDFS和HBase中的PB级大数据。已有的Hive系统虽然也提供了SQL语义，但由于Hive底层执行使用的是MapReduce引擎，仍然是一个批处理过程，难以满足查询的交互性。相比之下，Impala的最大特点也是最大卖点就是它的快速。
HUE
	Hue是cdh专门的一套web管理器，它包括3个部分hue ui，hue server，hue db。hue提供所有的cdh组件的shell界面的接口。你可以在hue编写mr，查看修改hdfs的文件，管理Hive的元数据，运行Sqoop，编写Oozie工作流等大量工作。














